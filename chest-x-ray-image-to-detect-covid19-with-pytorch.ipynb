{"cells":[{"metadata":{"id":"sTVhlNtdri3w"},"cell_type":"markdown","source":"# **Using pytorch detecting Covid-19 Infected Lungs from Normal Lungs with Chest X-Ray**"},{"metadata":{"id":"FrO_RdeCrCNI","trusted":true},"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"tVinQ9F7ySj6","trusted":true},"cell_type":"code","source":"print(torch.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"qKnF2bLUsQ-Q"},"cell_type":"markdown","source":" ## Importing kaggle Data Train_Val Set"},{"metadata":{},"cell_type":"markdown","source":"### base folder\n### ../kaggle/input/ -- cannot write i.e cannot create Folder\n\n### Output folder\n### /kaggle/working/temp -- create your folder here."},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/working/","execution_count":null,"outputs":[]},{"metadata":{"id":"67SuSQWEs_TP","trusted":true},"cell_type":"code","source":"!mkdir temp/Xray_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l /kaggle/working/temp/Xray_train_data","execution_count":null,"outputs":[]},{"metadata":{"id":"fGrAf9pptGEX","trusted":true},"cell_type":"code","source":"!cp -R \"../input/covid19-radiography-database/COVID-19 Radiography Database/COVID-19\" \"/kaggle/working/temp/Xray_train_data\"","execution_count":null,"outputs":[]},{"metadata":{"id":"89UP3sUHtSc_","trusted":true},"cell_type":"code","source":"!cp -R \"../input/covid19-radiography-database/COVID-19 Radiography Database/NORMAL\" \"/kaggle/working/temp/Xray_train_data\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls \"/kaggle/working/temp/Xray_train_data\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -1 \"/kaggle/working/temp/Xray_train_data/COVID-19\"| wc -l ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -1 \"/kaggle/working/temp/Xray_train_data/NORMAL\"| wc -l ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deleting extra image\n!find \"/kaggle/working/temp/Xray_train_data/NORMAL\" -type f -print0 | sort -zR | tail -zn +220 | xargs -0 rm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -1 \"/kaggle/working/temp/Xray_train_data/NORMAL\"| wc -l ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To deal with imbalanced dataset, I just took a lazy way out."},{"metadata":{"id":"Txo-Ok26yCnQ"},"cell_type":"markdown","source":"## **Starting Actual work**"},{"metadata":{"id":"2IC4h81qx4O_","trusted":true},"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"id":"2NWur8C_AYvs"},"cell_type":"markdown","source":"### Directing to Train Folder\n##### Works similiar as ImageData Generator of Keras"},{"metadata":{"id":"KCx7r6Vr-U9m","trusted":true},"cell_type":"code","source":"# Defining transform to resize 1024x1024 to 128x128\n# To change to Tensor\ntransform=transforms.Compose([\n                              transforms.Resize([64,64]),\n                              transforms.ToTensor()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_val_path=\"/kaggle/working/temp/Xray_train_data\"","execution_count":null,"outputs":[]},{"metadata":{"id":"Oeb4-tW9AqWr","trusted":true},"cell_type":"code","source":"dataset=ImageFolder(train_val_path,transform=transform)","execution_count":null,"outputs":[]},{"metadata":{"id":"1DgFhtrbBZcd","trusted":true},"cell_type":"code","source":"len(dataset)","execution_count":null,"outputs":[]},{"metadata":{"id":"SGBWiQgDBDn6","outputId":"dabb3d59-0a28-4b5f-85b5-80c55f95a4b4","trusted":true},"cell_type":"code","source":"# Checking For Samples\nimg0,label0=dataset[10]\nprint(img0.shape,label0)\nimg1,label1=dataset[300]\nprint(img1.shape,label1)\nprint(\"*\"*60)\nprint(dataset.classes)#list out all the classes","execution_count":null,"outputs":[]},{"metadata":{"id":"HwLW33rSBPrS","outputId":"bc3589ba-31f4-4d9d-82b6-02d8bb6ade68","trusted":true},"cell_type":"code","source":"def show(img,label):\n  print(\"label-->\",dataset.classes[label])\n  plt.imshow(img.permute(1,2,0))\n\nshow(*dataset[144])\n# 0-->Covid-19;1-->Normal","execution_count":null,"outputs":[]},{"metadata":{"id":"MWzHlZG-Jd5I"},"cell_type":"markdown","source":"### Splitting Validation Set from Training Set"},{"metadata":{"id":"Es5w1er0E02y","outputId":"56daccd4-ec71-4873-b285-debb150af684","trusted":true},"cell_type":"code","source":"# Splitting the data into train and validation set\ndef split_train_val(tot_img,val_percentage=0.2,rnd=23):\n  # Here indices are randomly permuted \n  number_of_val=int(tot_img*val_percentage)\n  np.random.seed(rnd)\n  indexs=np.random.permutation(tot_img)\n  return indexs[number_of_val:],indexs[:number_of_val]\n\nrandomness=12\nval_per=0.5\ntrain_indices,validation_indices=split_train_val(len(dataset),val_per,randomness)\nprint(validation_indices[:5])","execution_count":null,"outputs":[]},{"metadata":{"id":"G8k9H6J4OnyY","trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler #samples randomly from given indices\nfrom torch.utils.data.dataloader import DataLoader # loads the data from sampler","execution_count":null,"outputs":[]},{"metadata":{"id":"RymvterAO_5y","trusted":true},"cell_type":"code","source":"# Subset random sampler takes the indices to pick the data\n# dataloader loads with the main dataset, with batch size and the sampler object\nbatch_size=16\n# Training Part\ntrain_sampler=SubsetRandomSampler(train_indices)\ntrain_ds=DataLoader(dataset,batch_size,sampler=train_sampler)\n\n# Validation Part\nval_sampler=SubsetRandomSampler(validation_indices)\nval_ds=DataLoader(dataset,batch_size,sampler=val_sampler)","execution_count":null,"outputs":[]},{"metadata":{"id":"3XqrluI6oCqf"},"cell_type":"markdown","source":"## **Applying CNN**"},{"metadata":{"id":"mTJhfJmKTeUN","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"id":"NFS7I1Z-oQRq","trusted":true},"cell_type":"code","source":"# 1st layer of Conv2d\n# 1st Argument is number of color channel for RGB=3, for BW=1\n# 2nd Argument if number of filters, 3rd is filter size\n# how to calculate its output directly to Linear Unit\n# image=3x64x64-->64-3(filter_size)+1=62. So, output is 62x62xnumber of filter\n# then 62x62xnum_of_filter-->maxpool(2,2)-->62/2=31-->8*31*31\n# for same layer number of filter of output is input of new channel\n# for conv to linear layer the above calculation is reqd.\n\n\"\"\"\n# Use nn.Sequential for implementation\n# Though I myself doesnt like it.\nmodel=nn.Sequential(\n        nn.Conv2d(3,8,3), \n        nn.ReLU(),\n        nn.MaxPool2d(2,2),\n        nn.Flatten(start_dim=1), #.view(-1,)\n        nn.Linear(8*31*31,2)\n\n)\n\"\"\"\n# Recommended to use Object Oriented Neural Network\n# pytorch nn library provide with 2 component on abstarct level.\n# (i) is transformation i.e code (ii) Collection of weight - data\n# class Module base class for all nn module\n# Every neural network inherits from nn.Module class\nclass ConvNet(nn.Module):\n  def __init__(self):\n    # super here used access method of parent class\n    # dont worry much just boiler plate\n    super(ConvNet,self).__init__()\n    # In conv layer in_channels== input; out_channels=output; kernel_size=filter size\n    self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3)\n    # Linear layer in_features is input, how 8*31*31 came is explained in above comment\n    # out_features= output\n    self.fc1=nn.Linear(in_features=8*31*31,out_features=32)\n    self.out=nn.Linear(in_features=32,out_features=2)\n\n  def forward(self,l):\n    # this method implements forward propagation\n    # So, layers are structured as such\n\n    # 1 Conv layer\n    # may be thinking self.conv1 is an layer object instance how can we call as if it a function\n    # Checkout python documents __call__ this special method is used, so that instances behaves like function\n    # __call__ this special method invokes anytime the object instance is called. This interacts with forward method.\n    l=self.conv1(l)\n    l=F.relu(l)\n    l=F.max_pool2d(l,kernel_size=2)\n\n    # linear and final layer\n    # -1 indicates, give any number of batch size\n    l=l.reshape(-1,8*31*31)\n    l=self.fc1(l)\n    l=self.out(l)\n\n    return l","execution_count":null,"outputs":[]},{"metadata":{"id":"yOL8s-SX_g3h","trusted":true},"cell_type":"code","source":"\nmodel=ConvNet()","execution_count":null,"outputs":[]},{"metadata":{"id":"yxKgnIIvq0og","trusted":true},"cell_type":"code","source":"# If gpu present then use it or else use cpu\n# if gpu not present dont run this cell\n\"\"\"def default_device():\n  if torch.cuda.is_available():\n    return torch.device(\"cuda:0\")\n  else:\n    return torch.device(\"cpu\")\n\ndevice=default_device()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"id":"L8VLyyaQtav2","trusted":true},"cell_type":"code","source":"# Loading model on GPU\nmodel.cuda()","execution_count":null,"outputs":[]},{"metadata":{"id":"2ghlTY54phtk","trusted":true},"cell_type":"code","source":"# Define loss and optimizer\nimport torch.optim as optim\nloss_type = nn.CrossEntropyLoss()\n# Adam optimizer is the combination of momentum with RMSprop and is more powerful\noptimizer = optim.Adam(model.parameters(), lr=0.0005)","execution_count":null,"outputs":[]},{"metadata":{"id":"qDBty2msr3Ng","trusted":true},"cell_type":"code","source":"for epoch in range(10):  \n# loop over the dataset multiple times\n    print(\"Epoch count-->\",epoch)\n    \n    for i, data in enumerate(train_ds):\n        \n        inputs, labels = data\n        # Loading inputs,labels on GPU\n        # inputs,labels=inputs.to(device),labels.to(device)\n        inputs,labels=inputs.cuda(),labels.cuda()\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Passing input into the model\n        outputs = model(inputs)\n        \n        # Caculating loss with crossentropy\n        loss = loss_type(outputs, labels)\n        \n        # calculates the gradient \n        loss.backward()\n        \n        # update the weights\n        optimizer.step()\n        \n\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"id":"kkgeIr2zWPCN","trusted":true},"cell_type":"code","source":"right = 0\ntotal = 0\nwith torch.no_grad():\n# Switching off the gradient part, so that backpropagation doesnt take place\n    for data in val_ds:\n        images, labels = data\n        images,labels=images.cuda(),labels.cuda()\n        \n        outputs = model(images)\n        \n        _, predicted = torch.max(outputs,dim=1)\n        total += labels.size(0)\n        # Caculating number of right prediction\n        right += (predicted == labels).sum()\n\nprint('Accuracy on the validation images: %d %%' % (\n    100 * right / total))","execution_count":null,"outputs":[]},{"metadata":{"id":"ba8BHByxuHCH"},"cell_type":"markdown","source":"## **Importing Test data and testing on it**\n#### This is completely from different source from train,val data"},{"metadata":{"id":"k_1dXVR-wGT6","trusted":true},"cell_type":"code","source":"!mkdir temp/Xray_test_data","execution_count":null,"outputs":[]},{"metadata":{"id":"uwGA9QE8wQfY","trusted":true},"cell_type":"code","source":"!cp -R \"../input/chest-xray-for-covid19-detection/Dataset/Train/Covid\" \"/kaggle/working/temp/Xray_test_data\"","execution_count":null,"outputs":[]},{"metadata":{"id":"VIhchIKyw56o","trusted":true},"cell_type":"code","source":"!cp -R \"../input/chest-xray-for-covid19-detection/Dataset/Train/Normal\" \"/kaggle/working/temp/Xray_test_data\"","execution_count":null,"outputs":[]},{"metadata":{"id":"0YdmAuX7xQk_","trusted":true},"cell_type":"code","source":"!ls \"/kaggle/working/temp/Xray_test_data\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -1 \"/kaggle/working/temp/Xray_test_data/Covid\"| wc -l ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -1 \"/kaggle/working/temp/Xray_test_data/Normal\"| wc -l ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"/kaggle/working/temp/Xray_test_data\"","execution_count":null,"outputs":[]},{"metadata":{"id":"-jtP_H9Asa7V","trusted":true},"cell_type":"code","source":"transform=transforms.Compose([\n                              transforms.Resize([64,64]),\n                              transforms.ToTensor()\n])\ntest_dataset=ImageFolder(test_path,transform=transform)","execution_count":null,"outputs":[]},{"metadata":{"id":"4-EPy-1jsz39","trusted":true},"cell_type":"code","source":"len(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"id":"YwjClGzqsz_D","trusted":true},"cell_type":"code","source":"# Checking For Samples\nimg0,label0=test_dataset[0]\nprint(img0.shape,label0)\nimg1,label1=test_dataset[150]\nprint(img1.shape,label1)\nprint(\"*\"*60)\nprint(test_dataset.classes)#list out all the classes","execution_count":null,"outputs":[]},{"metadata":{"id":"DNBwBPu-sz8t","trusted":true},"cell_type":"code","source":"batch_size=32\n# Training Part\ntest_ds=DataLoader(test_dataset,batch_size)","execution_count":null,"outputs":[]},{"metadata":{"id":"8kGw6HCgszoC","trusted":true},"cell_type":"code","source":"right_test = 0\ntotal_test = 0\nwith torch.no_grad():\n    for data in test_ds:\n        images, labels_test = data\n        #images,labels_test=images.to(device),labels_test.to(device)\n        images,labels_test=images.cuda(),labels_test.cuda()\n        outputs_test = model(images)\n        _, predicted_test = torch.max(outputs_test, 1)\n        total_test += labels_test.size(0)\n        right_test += (predicted_test == labels_test).sum()\n\nprint('Accuracy on the Test images: %d %%' % (\n    100 * right_test / total_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### If you are forking this notebook, and do comment, if its using GPU.\n### In my kaggle kernel it isnt"},{"metadata":{},"cell_type":"markdown","source":"## If helped, do give an upvote. It means a lot."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}